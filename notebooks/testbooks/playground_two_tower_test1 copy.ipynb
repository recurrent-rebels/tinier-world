{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfe020f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from psycopg2.extras import DictCursor\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b06f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to user_data\n",
    "connection = psycopg2.connect(host=\"localhost\", user=\"root\", port=5432, database=\"W9sV6cL2dX\", password=\"E5rG7tY3fH\")\n",
    "cursor = connection.cursor(cursor_factory=DictCursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd3e2a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "select_query = \"SELECT ts.user_id, ts.item_id, ts.time_spent, u.*, ie.* \\\n",
    "FROM time_spent AS ts \\\n",
    "JOIN users AS u ON ts.user_id = u.id \\\n",
    "JOIN item_embeddings AS ie ON ts.item_id = ie.item_id;\"\n",
    "cursor.execute(select_query)\n",
    "data = cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31810e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22857</td>\n",
       "      <td>af427d2e-d34c-40a7-aabf-ceab900e3389</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>FibonacciFlats</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[-0.20604084432125092, -0.8583592772483826, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43885</td>\n",
       "      <td>cb91fe20-d5df-4a80-b173-bb07bf5c5134</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7141339778900146, -1.4657678604125977, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43273</td>\n",
       "      <td>361ebe6a-294b-4c15-8935-21c6c2709a45</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>FibonacciFlats</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[-0.8985607028007507, 0.19602474570274353, 0.4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                               item_id  time_spent  gender  \\\n",
       "0    22857  af427d2e-d34c-40a7-aabf-ceab900e3389           0  female   \n",
       "1    43885  cb91fe20-d5df-4a80-b173-bb07bf5c5134           0    None   \n",
       "2    43273  361ebe6a-294b-4c15-8935-21c6c2709a45           0    male   \n",
       "\n",
       "          country   age                                          embedding  \n",
       "0  FibonacciFlats  50.0  [-0.20604084432125092, -0.8583592772483826, -1...  \n",
       "1            None   NaN  [-0.7141339778900146, -1.4657678604125977, -1....  \n",
       "2  FibonacciFlats  40.0  [-0.8985607028007507, 0.19602474570274353, 0.4...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_col = ['user_id','item_id', 'time_spent','id' ,'gender', 'country', 'age', 'item_id2','embedding','time_stamp']\n",
    "data_df = pd.DataFrame(data, columns=data_col)\n",
    "data_df = data_df.drop(columns=['id', 'time_stamp', 'item_id2'])\n",
    "data_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdc84d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time_spent</th>\n",
       "      <th>gender</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>embedding</th>\n",
       "      <th>gender_encode</th>\n",
       "      <th>country_encode</th>\n",
       "      <th>age_normalized</th>\n",
       "      <th>time_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22857</td>\n",
       "      <td>af427d2e-d34c-40a7-aabf-ceab900e3389</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>FibonacciFlats</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[-0.20604084432125092, -0.8583592772483826, -1...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43885</td>\n",
       "      <td>cb91fe20-d5df-4a80-b173-bb07bf5c5134</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.7141339778900146, -1.4657678604125977, -1....</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43273</td>\n",
       "      <td>361ebe6a-294b-4c15-8935-21c6c2709a45</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>FibonacciFlats</td>\n",
       "      <td>40.0</td>\n",
       "      <td>[-0.8985607028007507, 0.19602474570274353, 0.4...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14230</td>\n",
       "      <td>31bebb98-9202-4e78-b193-c1d7e650360d</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-1.7180352210998535, 0.4146166145801544, -0.5...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19641</td>\n",
       "      <td>3a72d1cf-02b9-4b6b-bf0d-858961c107e9</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>GraphTown</td>\n",
       "      <td>47.0</td>\n",
       "      <td>[-1.584043264389038, -1.3862628936767578, -2.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                               item_id  time_spent  gender  \\\n",
       "0    22857  af427d2e-d34c-40a7-aabf-ceab900e3389           0  female   \n",
       "1    43885  cb91fe20-d5df-4a80-b173-bb07bf5c5134           0    None   \n",
       "2    43273  361ebe6a-294b-4c15-8935-21c6c2709a45           0    male   \n",
       "3    14230  31bebb98-9202-4e78-b193-c1d7e650360d           0    None   \n",
       "4    19641  3a72d1cf-02b9-4b6b-bf0d-858961c107e9           0    male   \n",
       "\n",
       "          country   age                                          embedding  \\\n",
       "0  FibonacciFlats  50.0  [-0.20604084432125092, -0.8583592772483826, -1...   \n",
       "1            None   NaN  [-0.7141339778900146, -1.4657678604125977, -1....   \n",
       "2  FibonacciFlats  40.0  [-0.8985607028007507, 0.19602474570274353, 0.4...   \n",
       "3            None   NaN  [-1.7180352210998535, 0.4146166145801544, -0.5...   \n",
       "4       GraphTown  47.0  [-1.584043264389038, -1.3862628936767578, -2.0...   \n",
       "\n",
       "   gender_encode  country_encode  age_normalized  time_normalized  \n",
       "0              0               3        0.544444              0.0  \n",
       "1              3               8             NaN              0.0  \n",
       "2              1               3        0.433333              0.0  \n",
       "3              3               8             NaN              0.0  \n",
       "4              1               4        0.511111              0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = list(set(data_df.country))\n",
    "genders = list(set(data_df.gender))\n",
    "gender_encoder = LabelEncoder()\n",
    "gender_encoder.fit(genders)\n",
    "country_encoder = LabelEncoder()\n",
    "country_encoder.fit(countries)\n",
    "age_scaler = MinMaxScaler()\n",
    "time_scaler = MinMaxScaler()\n",
    "\n",
    "data_df['gender_encode'] = gender_encoder.transform(data_df['gender'])\n",
    "data_df['country_encode'] = country_encoder.transform(data_df['country'])\n",
    "data_df['age_normalized'] = age_scaler.fit_transform(data_df[['age']])\n",
    "data_df['time_normalized'] = age_scaler.fit_transform(data_df[['time_spent']])\n",
    "data_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dcaa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = data_df.apply(lambda row: np.append(row['item_id'], row['embedding']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30475241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55f0bd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = data_df[['gender_encode', 'country_encode', 'age_normalized']]\n",
    "item_features = data_df.apply(lambda row: np.append(row['item_id'], row['embedding']), axis=1) #data_df[['item_id', 'embedding']]\n",
    "targets = data_df['time_normalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91bed31b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [af427d2e-d34c-40a7-aabf-ceab900e3389, -0.2060...\n",
       "1    [cb91fe20-d5df-4a80-b173-bb07bf5c5134, -0.7141...\n",
       "2    [361ebe6a-294b-4c15-8935-21c6c2709a45, -0.8985...\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_features[:3]\n",
    "item_features[:3]\n",
    "# targets[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9037c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed) #for CPU\n",
    "    torch.cuda.manual_seed(seed) #for GPU\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Two-tower model architecture\n",
    "class TwoTowerNetwork(nn.Module):\n",
    "    def __init__(self, user_input_dim, item_input_dim, output_dim):\n",
    "        super(TwoTowerNetwork, self).__init__()\n",
    "\n",
    "        hidden_dim = 128  # example value, adjust based on your requirement\n",
    "\n",
    "        # User tower\n",
    "        self.user_tower = nn.Sequential(\n",
    "            nn.Linear(user_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "        # Item tower\n",
    "        self.item_tower = nn.Sequential(\n",
    "            nn.Linear(item_input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, user_input, item_input):\n",
    "        # User tower\n",
    "        user_output = self.user_tower(user_input)\n",
    "\n",
    "        # Item tower\n",
    "        item_output = self.item_tower(item_input)\n",
    "\n",
    "        # Normalize the embeddings (this is necessary for cosine similarity)\n",
    "        user_output = F.normalize(user_output, dim=1)\n",
    "        item_output = F.normalize(item_output, dim=1)\n",
    "\n",
    "        return user_output, item_output\n",
    "\n",
    "# Custom dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, user_features, item_features, targets):\n",
    "        # df_test = data_df.apply(lambda row: np.append(row['item_id'], row['embedding']), axis=1)\n",
    "\n",
    "        self.user_features = user_features\n",
    "        self.item_features = item_features\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_features[idx], self.item_features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476360b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "user_feature_dim = 3 # age, F/M, country\n",
    "item_feature_dim = 1001 # item_id, item_type, item_features\n",
    "embedding_dim = 100\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "seed_everything(seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5ea3e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'new_feature'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msymmetric_difference\u001b[39m(\u001b[39mself\u001b[39m, other, result_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sort\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3644\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3645\u001b[0m \u001b[39m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[1;32m   3646\u001b[0m \n\u001b[1;32m   3647\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   3648\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[39m    other : Index or array-like\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \u001b[39m    result_name : str\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[39m    sort : False or None, default None\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m \u001b[39m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[0;32m-> 3653\u001b[0m \u001b[39m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[1;32m   3654\u001b[0m \u001b[39m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \n\u001b[1;32m   3656\u001b[0m \u001b[39m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m \u001b[39m          from comparing incomparable elements.\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m \u001b[39m        * False : Do not sort the result.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m \n\u001b[1;32m   3660\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m   3661\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m   3662\u001b[0m \u001b[39m    symmetric_difference : Index\u001b[39;00m\n\u001b[1;32m   3663\u001b[0m \n\u001b[1;32m   3664\u001b[0m \u001b[39m    Notes\u001b[39;00m\n\u001b[1;32m   3665\u001b[0m \u001b[39m    -----\u001b[39;00m\n\u001b[1;32m   3666\u001b[0m \u001b[39m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[1;32m   3667\u001b[0m \u001b[39m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[1;32m   3668\u001b[0m \u001b[39m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m \u001b[39m    dropped.\u001b[39;00m\n\u001b[1;32m   3670\u001b[0m \n\u001b[1;32m   3671\u001b[0m \u001b[39m    Examples\u001b[39;00m\n\u001b[1;32m   3672\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   3673\u001b[0m \u001b[39m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[1;32m   3674\u001b[0m \u001b[39m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[1;32m   3675\u001b[0m \u001b[39m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[1;32m   3676\u001b[0m \u001b[39m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[1;32m   3677\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3678\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_sort_keyword(sort)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'new_feature'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m TwoTowerNetwork(user_feature_dim, item_feature_dim, embedding_dim)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Create the custom dataset and data loader\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m dataset \u001b[39m=\u001b[39m CustomDataset(item_features, item_features,targets)\n\u001b[1;32m      6\u001b[0m data_loader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[39m# Initialize the optimizer and loss function\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, user_features, item_features, targets)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, user_features, item_features, targets):\n\u001b[1;32m     46\u001b[0m     \u001b[39m# df_test = data_df.apply(lambda row: np.append(row['item_id'], row['embedding']), axis=1)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_features \u001b[39m=\u001b[39m user_features\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_features \u001b[39m=\u001b[39m data_df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: np\u001b[39m.\u001b[39;49mappend(row[\u001b[39m'\u001b[39;49m\u001b[39mitem_id\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mnew_feature\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m targets\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9411\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   9412\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9413\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9418\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   9419\u001b[0m ):\n\u001b[1;32m   9420\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9421\u001b[0m \u001b[39m    Apply a function along an axis of the DataFrame.\u001b[39;00m\n\u001b[1;32m   9422\u001b[0m \n\u001b[0;32m-> 9423\u001b[0m \u001b[39m    Objects passed to the function are Series objects whose index is\u001b[39;00m\n\u001b[1;32m   9424\u001b[0m \u001b[39m    either the DataFrame's index (``axis=0``) or the DataFrame's columns\u001b[39;00m\n\u001b[1;32m   9425\u001b[0m \u001b[39m    (``axis=1``). By default (``result_type=None``), the final return type\u001b[39;00m\n\u001b[1;32m   9426\u001b[0m \u001b[39m    is inferred from the return type of the applied function. Otherwise,\u001b[39;00m\n\u001b[1;32m   9427\u001b[0m \u001b[39m    it depends on the `result_type` argument.\u001b[39;00m\n\u001b[1;32m   9428\u001b[0m \n\u001b[1;32m   9429\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   9430\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m   9431\u001b[0m \u001b[39m    func : function\u001b[39;00m\n\u001b[1;32m   9432\u001b[0m \u001b[39m        Function to apply to each column or row.\u001b[39;00m\n\u001b[1;32m   9433\u001b[0m \u001b[39m    axis : {0 or 'index', 1 or 'columns'}, default 0\u001b[39;00m\n\u001b[1;32m   9434\u001b[0m \u001b[39m        Axis along which the function is applied:\u001b[39;00m\n\u001b[1;32m   9435\u001b[0m \n\u001b[1;32m   9436\u001b[0m \u001b[39m        * 0 or 'index': apply function to each column.\u001b[39;00m\n\u001b[1;32m   9437\u001b[0m \u001b[39m        * 1 or 'columns': apply function to each row.\u001b[39;00m\n\u001b[1;32m   9438\u001b[0m \n\u001b[1;32m   9439\u001b[0m \u001b[39m    raw : bool, default False\u001b[39;00m\n\u001b[1;32m   9440\u001b[0m \u001b[39m        Determines if row or column is passed as a Series or ndarray object:\u001b[39;00m\n\u001b[1;32m   9441\u001b[0m \n\u001b[1;32m   9442\u001b[0m \u001b[39m        * ``False`` : passes each row or column as a Series to the\u001b[39;00m\n\u001b[1;32m   9443\u001b[0m \u001b[39m          function.\u001b[39;00m\n\u001b[1;32m   9444\u001b[0m \u001b[39m        * ``True`` : the passed function will receive ndarray objects\u001b[39;00m\n\u001b[1;32m   9445\u001b[0m \u001b[39m          instead.\u001b[39;00m\n\u001b[1;32m   9446\u001b[0m \u001b[39m          If you are just applying a NumPy reduction function this will\u001b[39;00m\n\u001b[1;32m   9447\u001b[0m \u001b[39m          achieve much better performance.\u001b[39;00m\n\u001b[1;32m   9448\u001b[0m \n\u001b[1;32m   9449\u001b[0m \u001b[39m    result_type : {'expand', 'reduce', 'broadcast', None}, default None\u001b[39;00m\n\u001b[1;32m   9450\u001b[0m \u001b[39m        These only act when ``axis=1`` (columns):\u001b[39;00m\n\u001b[1;32m   9451\u001b[0m \n\u001b[1;32m   9452\u001b[0m \u001b[39m        * 'expand' : list-like results will be turned into columns.\u001b[39;00m\n\u001b[1;32m   9453\u001b[0m \u001b[39m        * 'reduce' : returns a Series if possible rather than expanding\u001b[39;00m\n\u001b[1;32m   9454\u001b[0m \u001b[39m          list-like results. This is the opposite of 'expand'.\u001b[39;00m\n\u001b[1;32m   9455\u001b[0m \u001b[39m        * 'broadcast' : results will be broadcast to the original shape\u001b[39;00m\n\u001b[1;32m   9456\u001b[0m \u001b[39m          of the DataFrame, the original index and columns will be\u001b[39;00m\n\u001b[1;32m   9457\u001b[0m \u001b[39m          retained.\u001b[39;00m\n\u001b[1;32m   9458\u001b[0m \n\u001b[1;32m   9459\u001b[0m \u001b[39m        The default behaviour (None) depends on the return value of the\u001b[39;00m\n\u001b[1;32m   9460\u001b[0m \u001b[39m        applied function: list-like results will be returned as a Series\u001b[39;00m\n\u001b[1;32m   9461\u001b[0m \u001b[39m        of those. However if the apply function returns a Series these\u001b[39;00m\n\u001b[1;32m   9462\u001b[0m \u001b[39m        are expanded to columns.\u001b[39;00m\n\u001b[1;32m   9463\u001b[0m \u001b[39m    args : tuple\u001b[39;00m\n\u001b[1;32m   9464\u001b[0m \u001b[39m        Positional arguments to pass to `func` in addition to the\u001b[39;00m\n\u001b[1;32m   9465\u001b[0m \u001b[39m        array/series.\u001b[39;00m\n\u001b[1;32m   9466\u001b[0m \u001b[39m    **kwargs\u001b[39;00m\n\u001b[1;32m   9467\u001b[0m \u001b[39m        Additional keyword arguments to pass as keywords arguments to\u001b[39;00m\n\u001b[1;32m   9468\u001b[0m \u001b[39m        `func`.\u001b[39;00m\n\u001b[1;32m   9469\u001b[0m \n\u001b[1;32m   9470\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m   9471\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m   9472\u001b[0m \u001b[39m    Series or DataFrame\u001b[39;00m\n\u001b[1;32m   9473\u001b[0m \u001b[39m        Result of applying ``func`` along the given axis of the\u001b[39;00m\n\u001b[1;32m   9474\u001b[0m \u001b[39m        DataFrame.\u001b[39;00m\n\u001b[1;32m   9475\u001b[0m \n\u001b[1;32m   9476\u001b[0m \u001b[39m    See Also\u001b[39;00m\n\u001b[1;32m   9477\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   9478\u001b[0m \u001b[39m    DataFrame.applymap: For elementwise operations.\u001b[39;00m\n\u001b[1;32m   9479\u001b[0m \u001b[39m    DataFrame.aggregate: Only perform aggregating type operations.\u001b[39;00m\n\u001b[1;32m   9480\u001b[0m \u001b[39m    DataFrame.transform: Only perform transforming type operations.\u001b[39;00m\n\u001b[1;32m   9481\u001b[0m \n\u001b[1;32m   9482\u001b[0m \u001b[39m    Notes\u001b[39;00m\n\u001b[1;32m   9483\u001b[0m \u001b[39m    -----\u001b[39;00m\n\u001b[1;32m   9484\u001b[0m \u001b[39m    Functions that mutate the passed object can produce unexpected\u001b[39;00m\n\u001b[1;32m   9485\u001b[0m \u001b[39m    behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`\u001b[39;00m\n\u001b[1;32m   9486\u001b[0m \u001b[39m    for more details.\u001b[39;00m\n\u001b[1;32m   9487\u001b[0m \n\u001b[1;32m   9488\u001b[0m \u001b[39m    Examples\u001b[39;00m\n\u001b[1;32m   9489\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   9490\u001b[0m \u001b[39m    >>> df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\u001b[39;00m\n\u001b[1;32m   9491\u001b[0m \u001b[39m    >>> df\u001b[39;00m\n\u001b[1;32m   9492\u001b[0m \u001b[39m       A  B\u001b[39;00m\n\u001b[1;32m   9493\u001b[0m \u001b[39m    0  4  9\u001b[39;00m\n\u001b[1;32m   9494\u001b[0m \u001b[39m    1  4  9\u001b[39;00m\n\u001b[1;32m   9495\u001b[0m \u001b[39m    2  4  9\u001b[39;00m\n\u001b[1;32m   9496\u001b[0m \n\u001b[1;32m   9497\u001b[0m \u001b[39m    Using a numpy universal function (in this case the same as\u001b[39;00m\n\u001b[1;32m   9498\u001b[0m \u001b[39m    ``np.sqrt(df)``):\u001b[39;00m\n\u001b[1;32m   9499\u001b[0m \n\u001b[1;32m   9500\u001b[0m \u001b[39m    >>> df.apply(np.sqrt)\u001b[39;00m\n\u001b[1;32m   9501\u001b[0m \u001b[39m         A    B\u001b[39;00m\n\u001b[1;32m   9502\u001b[0m \u001b[39m    0  2.0  3.0\u001b[39;00m\n\u001b[1;32m   9503\u001b[0m \u001b[39m    1  2.0  3.0\u001b[39;00m\n\u001b[1;32m   9504\u001b[0m \u001b[39m    2  2.0  3.0\u001b[39;00m\n\u001b[1;32m   9505\u001b[0m \n\u001b[1;32m   9506\u001b[0m \u001b[39m    Using a reducing function on either axis\u001b[39;00m\n\u001b[1;32m   9507\u001b[0m \n\u001b[1;32m   9508\u001b[0m \u001b[39m    >>> df.apply(np.sum, axis=0)\u001b[39;00m\n\u001b[1;32m   9509\u001b[0m \u001b[39m    A    12\u001b[39;00m\n\u001b[1;32m   9510\u001b[0m \u001b[39m    B    27\u001b[39;00m\n\u001b[1;32m   9511\u001b[0m \u001b[39m    dtype: int64\u001b[39;00m\n\u001b[1;32m   9512\u001b[0m \n\u001b[1;32m   9513\u001b[0m \u001b[39m    >>> df.apply(np.sum, axis=1)\u001b[39;00m\n\u001b[1;32m   9514\u001b[0m \u001b[39m    0    13\u001b[39;00m\n\u001b[1;32m   9515\u001b[0m \u001b[39m    1    13\u001b[39;00m\n\u001b[1;32m   9516\u001b[0m \u001b[39m    2    13\u001b[39;00m\n\u001b[1;32m   9517\u001b[0m \u001b[39m    dtype: int64\u001b[39;00m\n\u001b[1;32m   9518\u001b[0m \n\u001b[1;32m   9519\u001b[0m \u001b[39m    Returning a list-like will result in a Series\u001b[39;00m\n\u001b[1;32m   9520\u001b[0m \n\u001b[1;32m   9521\u001b[0m \u001b[39m    >>> df.apply(lambda x: [1, 2], axis=1)\u001b[39;00m\n\u001b[1;32m   9522\u001b[0m \u001b[39m    0    [1, 2]\u001b[39;00m\n\u001b[1;32m   9523\u001b[0m \u001b[39m    1    [1, 2]\u001b[39;00m\n\u001b[1;32m   9524\u001b[0m \u001b[39m    2    [1, 2]\u001b[39;00m\n\u001b[1;32m   9525\u001b[0m \u001b[39m    dtype: object\u001b[39;00m\n\u001b[1;32m   9526\u001b[0m \n\u001b[1;32m   9527\u001b[0m \u001b[39m    Passing ``result_type='expand'`` will expand list-like results\u001b[39;00m\n\u001b[1;32m   9528\u001b[0m \u001b[39m    to columns of a Dataframe\u001b[39;00m\n\u001b[1;32m   9529\u001b[0m \n\u001b[1;32m   9530\u001b[0m \u001b[39m    >>> df.apply(lambda x: [1, 2], axis=1, result_type='expand')\u001b[39;00m\n\u001b[1;32m   9531\u001b[0m \u001b[39m       0  1\u001b[39;00m\n\u001b[1;32m   9532\u001b[0m \u001b[39m    0  1  2\u001b[39;00m\n\u001b[1;32m   9533\u001b[0m \u001b[39m    1  1  2\u001b[39;00m\n\u001b[1;32m   9534\u001b[0m \u001b[39m    2  1  2\u001b[39;00m\n\u001b[1;32m   9535\u001b[0m \n\u001b[1;32m   9536\u001b[0m \u001b[39m    Returning a Series inside the function is similar to passing\u001b[39;00m\n\u001b[1;32m   9537\u001b[0m \u001b[39m    ``result_type='expand'``. The resulting column names\u001b[39;00m\n\u001b[1;32m   9538\u001b[0m \u001b[39m    will be the Series index.\u001b[39;00m\n\u001b[1;32m   9539\u001b[0m \n\u001b[1;32m   9540\u001b[0m \u001b[39m    >>> df.apply(lambda x: pd.Series([1, 2], index=['foo', 'bar']), axis=1)\u001b[39;00m\n\u001b[1;32m   9541\u001b[0m \u001b[39m       foo  bar\u001b[39;00m\n\u001b[1;32m   9542\u001b[0m \u001b[39m    0    1    2\u001b[39;00m\n\u001b[1;32m   9543\u001b[0m \u001b[39m    1    1    2\u001b[39;00m\n\u001b[1;32m   9544\u001b[0m \u001b[39m    2    1    2\u001b[39;00m\n\u001b[1;32m   9545\u001b[0m \n\u001b[1;32m   9546\u001b[0m \u001b[39m    Passing ``result_type='broadcast'`` will ensure the same shape\u001b[39;00m\n\u001b[1;32m   9547\u001b[0m \u001b[39m    result, whether list-like or scalar is returned by the function,\u001b[39;00m\n\u001b[1;32m   9548\u001b[0m \u001b[39m    and broadcast it along the axis. The resulting column names will\u001b[39;00m\n\u001b[1;32m   9549\u001b[0m \u001b[39m    be the originals.\u001b[39;00m\n\u001b[1;32m   9550\u001b[0m \n\u001b[1;32m   9551\u001b[0m \u001b[39m    >>> df.apply(lambda x: [1, 2], axis=1, result_type='broadcast')\u001b[39;00m\n\u001b[1;32m   9552\u001b[0m \u001b[39m       A  B\u001b[39;00m\n\u001b[1;32m   9553\u001b[0m \u001b[39m    0  1  2\u001b[39;00m\n\u001b[1;32m   9554\u001b[0m \u001b[39m    1  1  2\u001b[39;00m\n\u001b[1;32m   9555\u001b[0m \u001b[39m    2  1  2\u001b[39;00m\n\u001b[1;32m   9556\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   9557\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m     op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m         func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m         kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m class NDFrameApply(Apply):\n\u001b[1;32m    668\u001b[0m     \"\"\"\n\u001b[1;32m    669\u001b[0m     Methods shared by FrameApply and SeriesApply but\n\u001b[1;32m    670\u001b[0m     not GroupByApply or ResamplerWindowApply\n\u001b[1;32m    671\u001b[0m     \"\"\"\n\u001b[1;32m    673\u001b[0m     @property\n\u001b[1;32m    674\u001b[0m     def index(self) -> Index:\n\u001b[1;32m    675\u001b[0m         # error: Argument 1 to \"__get__\" of \"AxisProperty\" has incompatible type\n\u001b[1;32m    676\u001b[0m         # \"Union[Series, DataFrame, GroupBy[Any], SeriesGroupBy,\n\u001b[1;32m    677\u001b[0m         # DataFrameGroupBy, BaseWindow, Resampler]\"; expected \"Union[DataFrame,\n\u001b[0;32m--> 678\u001b[0m         # Series]\"\n\u001b[1;32m    679\u001b[0m         return self.obj.index  # type:ignore[arg-type]\n\u001b[1;32m    681\u001b[0m     @property\n\u001b[1;32m    682\u001b[0m     def agg_axis(self) -> Index:\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_empty_result\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    796\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    797\u001b[0m \u001b[39m    we have an empty result; at least 1 axis is 0\u001b[39;00m\n\u001b[0;32m--> 798\u001b[0m \n\u001b[1;32m    799\u001b[0m \u001b[39m    we will try to apply the function to an empty\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m    series in order to see if this is a reduction function\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    802\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mcallable\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf)\n\u001b[1;32m    804\u001b[0m     \u001b[39m# we are not asked to reduce or infer reduction\u001b[39;00m\n\u001b[1;32m    805\u001b[0m     \u001b[39m# so just return a copy of the existing object\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m should_reduce \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mreduce\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    812\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[0;32m--> 814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m should_reduce:\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    816\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[17], line 49\u001b[0m, in \u001b[0;36mCustomDataset.__init__.<locals>.<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, user_features, item_features, targets):\n\u001b[1;32m     46\u001b[0m     \u001b[39m# df_test = data_df.apply(lambda row: np.append(row['item_id'], row['embedding']), axis=1)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_features \u001b[39m=\u001b[39m user_features\n\u001b[0;32m---> 49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_features \u001b[39m=\u001b[39m data_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: np\u001b[39m.\u001b[39mappend(row[\u001b[39m'\u001b[39m\u001b[39mitem_id\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39;49m\u001b[39mnew_feature\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets \u001b[39m=\u001b[39m targets\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1005\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m-> 1007\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_with(key)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1109\u001b[0m \u001b[39mif\u001b[39;00m is_integer(key) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39minferred_type \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minteger\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1110\u001b[0m     \u001b[39m# positional setter\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_should_fallback_to_positional:\n\u001b[1;32m   1112\u001b[0m         \u001b[39m# GH#33469\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1114\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mTreating integers as positional in Series.__setitem__ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwith a Float64Index is deprecated. In a future version, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1116\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`series[an_int] = val` will insert a new key into the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1117\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSeries. Use `series.iloc[an_int] = val` to treat the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1118\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mkey as positional.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1119\u001b[0m             \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1120\u001b[0m             stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1121\u001b[0m         )\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# can't use _mgr.setitem_inplace yet bc could have *both*\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[39m#  KeyError and then ValueError, xref GH#45070\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_values(key, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/tiny/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3643\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msymmetric_difference\u001b[39m(\u001b[39mself\u001b[39m, other, result_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sort\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   3644\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3645\u001b[0m \u001b[39m    Compute the symmetric difference of two Index objects.\u001b[39;00m\n\u001b[1;32m   3646\u001b[0m \n\u001b[1;32m   3647\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   3648\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m   3649\u001b[0m \u001b[39m    other : Index or array-like\u001b[39;00m\n\u001b[1;32m   3650\u001b[0m \u001b[39m    result_name : str\u001b[39;00m\n\u001b[1;32m   3651\u001b[0m \u001b[39m    sort : False or None, default None\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m \u001b[39m        Whether to sort the resulting index. By default, the\u001b[39;00m\n\u001b[1;32m   3653\u001b[0m \u001b[39m        values are attempted to be sorted, but any TypeError from\u001b[39;00m\n\u001b[1;32m   3654\u001b[0m \u001b[39m        incomparable elements is caught by pandas.\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m \n\u001b[1;32m   3656\u001b[0m \u001b[39m        * None : Attempt to sort the result, but catch any TypeErrors\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m \u001b[39m          from comparing incomparable elements.\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m \u001b[39m        * False : Do not sort the result.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m \n\u001b[1;32m   3660\u001b[0m \u001b[39m    Returns\u001b[39;00m\n\u001b[1;32m   3661\u001b[0m \u001b[39m    -------\u001b[39;00m\n\u001b[1;32m   3662\u001b[0m \u001b[39m    symmetric_difference : Index\u001b[39;00m\n\u001b[1;32m   3663\u001b[0m \n\u001b[1;32m   3664\u001b[0m \u001b[39m    Notes\u001b[39;00m\n\u001b[1;32m   3665\u001b[0m \u001b[39m    -----\u001b[39;00m\n\u001b[1;32m   3666\u001b[0m \u001b[39m    ``symmetric_difference`` contains elements that appear in either\u001b[39;00m\n\u001b[1;32m   3667\u001b[0m \u001b[39m    ``idx1`` or ``idx2`` but not both. Equivalent to the Index created by\u001b[39;00m\n\u001b[1;32m   3668\u001b[0m \u001b[39m    ``idx1.difference(idx2) | idx2.difference(idx1)`` with duplicates\u001b[39;00m\n\u001b[1;32m   3669\u001b[0m \u001b[39m    dropped.\u001b[39;00m\n\u001b[1;32m   3670\u001b[0m \n\u001b[1;32m   3671\u001b[0m \u001b[39m    Examples\u001b[39;00m\n\u001b[1;32m   3672\u001b[0m \u001b[39m    --------\u001b[39;00m\n\u001b[1;32m   3673\u001b[0m \u001b[39m    >>> idx1 = pd.Index([1, 2, 3, 4])\u001b[39;00m\n\u001b[1;32m   3674\u001b[0m \u001b[39m    >>> idx2 = pd.Index([2, 3, 4, 5])\u001b[39;00m\n\u001b[1;32m   3675\u001b[0m \u001b[39m    >>> idx1.symmetric_difference(idx2)\u001b[39;00m\n\u001b[1;32m   3676\u001b[0m \u001b[39m    Int64Index([1, 5], dtype='int64')\u001b[39;00m\n\u001b[1;32m   3677\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   3678\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_sort_keyword(sort)\n\u001b[1;32m   3679\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_can_do_setop(other)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'new_feature'"
     ]
    }
   ],
   "source": [
    "# Create the two-tower model\n",
    "model = TwoTowerNetwork(user_feature_dim, item_feature_dim, embedding_dim)\n",
    "\n",
    "# Create the custom dataset and data loader\n",
    "dataset = CustomDataset(item_features, item_features,targets)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd4381fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/libai/anaconda3/envs/RR/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/libai/anaconda3/envs/RR/lib/python3.9/site-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.34596234234049916\n",
      "Epoch 2/50, Loss: 0.2722171812783927\n",
      "Epoch 3/50, Loss: 0.24700147286057472\n",
      "Epoch 4/50, Loss: 0.22438882989808917\n",
      "Epoch 5/50, Loss: 0.21077052131295204\n",
      "Epoch 6/50, Loss: 0.19836670230142772\n",
      "Epoch 7/50, Loss: 0.18632018263451755\n",
      "Epoch 8/50, Loss: 0.17391128418967128\n",
      "Epoch 9/50, Loss: 0.17174197966232896\n",
      "Epoch 10/50, Loss: 0.15881346142850816\n",
      "Epoch 11/50, Loss: 0.1563244671560824\n",
      "Epoch 12/50, Loss: 0.15171588864177465\n",
      "Epoch 13/50, Loss: 0.1391624074894935\n",
      "Epoch 14/50, Loss: 0.137031233869493\n",
      "Epoch 15/50, Loss: 0.1351512351538986\n",
      "Epoch 16/50, Loss: 0.12719742092303932\n",
      "Epoch 17/50, Loss: 0.12180925044231117\n",
      "Epoch 18/50, Loss: 0.12113561015576124\n",
      "Epoch 19/50, Loss: 0.1166975584346801\n",
      "Epoch 20/50, Loss: 0.11368030915036798\n",
      "Epoch 21/50, Loss: 0.11073828092776239\n",
      "Epoch 22/50, Loss: 0.10603262367658317\n",
      "Epoch 23/50, Loss: 0.1043703742325306\n",
      "Epoch 24/50, Loss: 0.10124758118763566\n",
      "Epoch 25/50, Loss: 0.09947195276618004\n",
      "Epoch 26/50, Loss: 0.1015332406386733\n",
      "Epoch 27/50, Loss: 0.09640517341904342\n",
      "Epoch 28/50, Loss: 0.09633931936696172\n",
      "Epoch 29/50, Loss: 0.09601966291666031\n",
      "Epoch 30/50, Loss: 0.09607846639119089\n",
      "Epoch 31/50, Loss: 0.09634587378241122\n",
      "Epoch 32/50, Loss: 0.09380601719021797\n",
      "Epoch 33/50, Loss: 0.09535869909450412\n",
      "Epoch 34/50, Loss: 0.0939114224165678\n",
      "Epoch 35/50, Loss: 0.09326284192502499\n",
      "Epoch 36/50, Loss: 0.0924713130807504\n",
      "Epoch 37/50, Loss: 0.09108611894771457\n",
      "Epoch 38/50, Loss: 0.0915623470209539\n",
      "Epoch 39/50, Loss: 0.09072667243890464\n",
      "Epoch 40/50, Loss: 0.09054725558962673\n",
      "Epoch 41/50, Loss: 0.09108860325068235\n",
      "Epoch 42/50, Loss: 0.09001116151921451\n",
      "Epoch 43/50, Loss: 0.09086899156682193\n",
      "Epoch 44/50, Loss: 0.0899234008975327\n",
      "Epoch 45/50, Loss: 0.09024720638990402\n",
      "Epoch 46/50, Loss: 0.08981053752359003\n",
      "Epoch 47/50, Loss: 0.08970609947573394\n",
      "Epoch 48/50, Loss: 0.0905271724332124\n",
      "Epoch 49/50, Loss: 0.09129780204966664\n",
      "Epoch 50/50, Loss: 0.08905518229585141\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for user_feats, item_feats, targets in data_loader:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        user_embeds, item_embeds = model(user_feats, item_feats)\n",
    "        cos_sim = nn.functional.cosine_similarity(user_embeds, item_embeds)\n",
    "        loss = criterion(cos_sim.unsqueeze(1), targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663ce4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40aa0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
